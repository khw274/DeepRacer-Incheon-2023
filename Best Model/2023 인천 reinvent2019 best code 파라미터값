Action space type: Discrete

Action space
No.
        Steering angle (°)    Speed (m/s)
0	-26.0	              1.50
1	-26.0	      	      2.00
2	-13.0	              2.10
3	-13.0	              2.80
4	  0.0	              3.30
5	  0.0	              3.65
6	 13.0	              2.10
7	 13.0 	              2.80
8	 26.0	              1.50
9	 26.0	              2.00

(Hyperparameter)                                                        (Value)
Gradient descent batch size	                                        64
Entropy	                                                                0.05       # Entropy 더 수정해볼 가치가 있음
Discount factor	                                                        0.5
Loss type	                                                        Huber
Learning rate	                                                        0.0003
Number of experience episodes between each policy-updating iteration    20
Number of epochs	                                                10
